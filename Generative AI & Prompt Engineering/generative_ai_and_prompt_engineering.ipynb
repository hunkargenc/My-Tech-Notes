{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb817f26-446e-447c-8b6b-3e84dd92cbe1",
   "metadata": {},
   "source": [
    "# Generative AI & Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0b8ffd-840e-4a8e-bd19-1b6eb482c163",
   "metadata": {},
   "source": [
    "## Generative AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935feca8-eeda-4ea9-9681-6ceb3e754b59",
   "metadata": {},
   "source": [
    "**Generative AI:**\n",
    "\n",
    "- content focused\n",
    "- generating new sample\n",
    "- reasoning\n",
    "- forms of expression\n",
    "\n",
    "**Classical AI:**\n",
    "\n",
    "- data driven\n",
    "- pattern finding\n",
    "- prediction and classification\n",
    "- mathematical forms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203be7c8-38c2-4226-80df-36a5af911e61",
   "metadata": {},
   "source": [
    "To explain with an example, let's assume we have a training data set with classified and labeled cat images. With the **Generative Model**, we can generate a new cat image. Of course, this image produced has the characteristics of the training data set. **Discriminative Model** aims to find out which classification a cat picture has."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a5b285-2933-4fde-ac89-9226cfbe843e",
   "metadata": {},
   "source": [
    "### 1. Generative Adversarial Nets - GANs - (Çekişmeli Üretici Ağlar) - 2014"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cdacb1-2d11-4c4b-9f61-000948676b2c",
   "metadata": {},
   "source": [
    "Two separate artificial neural networks are put into competition with each other (Generator & Discriminator). While Generator synthesizes data from the data set, Discriminator tries to determine which class this synthesized data belongs to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fdde03-0cda-41af-9295-198829fda723",
   "metadata": {},
   "source": [
    "The aim is to reach the optimal level where both neural networks cannot deceive each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e2d54d-76e0-462b-a4f9-02534c0dad90",
   "metadata": {},
   "source": [
    "**Strengths**\n",
    "\n",
    "- It can synthesize high quality and realistic data samples.\n",
    "- Suitable for Supervised and Semi-Supervised Learning scenarios\n",
    "- It is especially effective in the production of synthetic visuals and synthetic videos.\n",
    "\n",
    "**Limitations**\n",
    "\n",
    "- It requires very large data sets and a lot of processing power to train.\n",
    "- Training processes can be complex and error-prone.\n",
    "- Synthetic image production also brings ethical problems.\n",
    "\n",
    "**Usage areas**\n",
    "\n",
    "- Synthetic image generation\n",
    "- Style recognition and style transfer\n",
    "- Synthetic data set production for training other models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37544290-c930-4b34-9705-ee1f0a3d5681",
   "metadata": {},
   "source": [
    "### 2. Transformer Architecture (Transformer Mimarisi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74a5dc1-b961-40e1-9856-f92464035d1d",
   "metadata": {},
   "source": [
    "The primary task they tackle is NLP. Transformers architecture was born as a result of the shortcomings of RNN, CNN, LSTM approaches. Attention is all you need!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6397388a-8dc3-4687-966e-07b461e70c93",
   "metadata": {},
   "source": [
    "**Attention Mechanism (Dikkat Mekanizması)**\n",
    "\n",
    "**Paralellizetion (Paralel İşleme)** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbcba7f-903d-488d-bc2e-0497e980a29d",
   "metadata": {},
   "source": [
    "Input Arrays (Text) - Output Arrays\n",
    "\n",
    "Embeddings - Embeddings\n",
    "\n",
    "Positional Embedding - Positional Embedding\n",
    "\n",
    "Encoder Blocks(Explore meaning) -> Decoder Blocks(Solve part by part, feed-forward(ileri besleme))  \n",
    "\n",
    "Softmax + Linear (Possibilities)\n",
    "\n",
    "Output (Text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefa63bf-112a-478c-8d4a-ce8161eac583",
   "metadata": {},
   "source": [
    "**Self-Attention (Öz Dikkat)**\n",
    "\n",
    "**Tokenization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3428de9-5ccf-48e6-a04c-1da6dfd625ef",
   "metadata": {},
   "source": [
    "**Strengths**\n",
    "- Can track connections and relationships within the dataset at scale beyond the local context\n",
    "- Unlike RNNs, data sequences can be processed in parallel and therefore scalable on modern parallel processing architectures.\n",
    "- A versatile architecture that can be used beyond the field of natural language processing\n",
    "\n",
    "**Limitations**\n",
    "- It requires extraordinary processing power for the training process.\n",
    "- Limitations in memory capacity can make it difficult to keep track of context for very long data sequences.\n",
    "- Synthetic image production brings with it some serious problems.\n",
    "\n",
    "**Usage areas**\n",
    "- Natural language communication interface\n",
    "- Image recognition and image processing\n",
    "- Voice recognition and translation services"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b91e892-16fd-4d18-8c8b-63e41abbcc9a",
   "metadata": {},
   "source": [
    "### 3. Large Language Models (LLMs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec6189e-b776-40a6-ba96-a9374daa7571",
   "metadata": {},
   "source": [
    "**Commercial models:** GBT 4 Turbo, GPT 3.5 Turbo, COMMAND, JURASSIC 2, GROK, CLAUDE 2.1, PaLM 2, LIMINOUS, INFLECTION 2\n",
    "\n",
    "**Open source models:** Llama 2, Mistral, Falcon, StableLM, Phi 2, BLOOM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56179468-f604-42f9-9359-7cd3cbb21a67",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a25e5d46-ebfb-4e9c-b43f-cd01c30b7a60",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2c1e9a6-ba9c-4073-a8c9-c8ef3e4bb398",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "258a71c9-0cf9-4edf-afc4-f581d810283e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd6dc6d8-8e37-42e5-819a-7eb3fbbf41f2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a5c9b00-33df-4a9f-814c-5c545d9565ce",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e102d68-2c5e-4b31-b1b4-14e39e129227",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb5b41b1-56dc-41d7-8ed4-e3c2f05a3a57",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f39b45d-323e-460c-ad47-2aabda5e5007",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03b48738-c915-4d0b-9115-f032edc923ac",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
